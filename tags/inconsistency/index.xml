<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Inconsistency on datanerds.io</title>
    <link>http://datanerds.io/tags/inconsistency/index.xml</link>
    <description>Recent content in Inconsistency on datanerds.io</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Copyright Â© 2016&lt;script&gt;new Date().getFullYear()&gt;2014&amp;&amp;document.write(&#34; - 1&#34;&#43;new Date().getFullYear());&lt;/script&gt; datanerds.io. &lt;a href=&#34;http://creativecommons.org/licenses/by/4.0/&#34;&gt;Some rights reserved&lt;/a&gt;.</copyright>
    <atom:link href="http://datanerds.io/tags/inconsistency/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>WAT - Cassandra: Row level consistency #$@&amp;%*!</title>
      <link>http://datanerds.io/post/cassandra-no-row-consistency/</link>
      <pubDate>Wed, 23 Nov 2016 19:45:48 -0700</pubDate>
      
      <guid>http://datanerds.io/post/cassandra-no-row-consistency/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;TL;DR&lt;/strong&gt; Cassandra &lt;strong&gt;&lt;em&gt;is not&lt;/em&gt;&lt;/strong&gt; row level consistent!!!&lt;/p&gt;

&lt;p&gt;We published a &lt;a href=&#34;http://datanerds.io/post/WAT-cassandra-1/&#34;&gt;blog post&lt;/a&gt; about some surprising and unexpected behaviors while using Apache Cassandra/DataStax Enterprise some weeks back. Recently, we encountered even more WAT moments and I believe this one is the most distressing.&lt;/p&gt;

&lt;p&gt;In a nutshell: &lt;strong&gt;We discovered corrupted data&lt;/strong&gt; and it took us a while to understand what was happening and why that data was corrupt. Let&amp;rsquo;s dive into the problem:&lt;/p&gt;

&lt;p&gt;Imagine a table with a primary key to identify an entity. Each entity can have a boolean state to mark it as locked. Additionally, each entity has a revision counter which is incremented on changes to the entity.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE TABLE locks (
    id text PRIMARY KEY,
    lock boolean,
    revision bigint
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For an initial lock of the entity &amp;lsquo;Tom&amp;rsquo; we execute an &lt;code&gt;INSERT&lt;/code&gt;. Since we need to make sure that no one else is obtaining the lock at the same time we make use of a Lightweight transaction (LWT) using &lt;code&gt;IF NOT EXISTS&lt;/code&gt;. It is possible that something goes wrong or our application even dies before releasing the lock, resulting in deadlocked entities where &lt;code&gt;lock&lt;/code&gt; stays &lt;code&gt;true&lt;/code&gt;. To ensure that the lock is released in such a case, we release the lock after a certain amount of time. This is achieved by using Cassandra&amp;rsquo;s Time To Live (&lt;code&gt;TTL&lt;/code&gt;) feature.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;INSERT INTO locks (id, lock, revision)
VALUES (&#39;Tom&#39;, true, 1)
IF NOT EXISTS USING TTL 20;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! After finishing some other calculations for our entity Tom, we release the lock via a simple UPDATE:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;UPDATE locks SET lock=false, revision=2 WHERE id=&#39;Tom&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The result should look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT * FROM locks WHERE id=&#39;Tom&#39;;

 id  | lock  | revision
-----+-------+----------
 Tom | False |        2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To our surprise this was not always the case. In ~0.1% of the rows the result looked like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT * FROM locks WHERE id=&#39;Tom&#39;;

 id  | lock | revision
-----+------+----------
 Tom | null |        2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Given the queries we are using, the row should not be in a state where lock is null and a revision is set at the same time.&lt;/p&gt;

&lt;p&gt;After deeper investigations of audit logs and a deep dive into the SSTables it turned out that we did run into a timestamp tie. The cluster node our client is talking to sees a stream of changes with two or more changes happening to the same entry in the lock table at the exact same time. Obviously the calculation we are doing in between acquiring the lock and releasing it is not taking enough time (microseconds). Interesting, so what is the resolution strategy for multiple updates at the same time? &lt;em&gt;&amp;ldquo;[&amp;hellip;] if there are two updates, the one with the lexically larger value is selected. [&amp;hellip;]&amp;rdquo;&lt;/em&gt; [1]&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;lexical larger value? LEXICAL LARGER VALUE??&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;So what happens to our statements? When the acquire and release of the lock happen at the same exact time, Cassandra will compare on &lt;strong&gt;&lt;em&gt;cell level&lt;/em&gt;&lt;/strong&gt;, I repeat, &lt;strong&gt;&lt;em&gt;CELL LEVEL&lt;/em&gt;&lt;/strong&gt; which one is greater and will choose the value for this cell from the query for the final state. For the lock column this means: &lt;code&gt;true &amp;gt; false&lt;/code&gt; so it will take that portion of the &lt;code&gt;INSERT&lt;/code&gt;. For the revision column the &lt;code&gt;UPDATE&lt;/code&gt; query will win since &lt;code&gt;2 &amp;gt; 1&lt;/code&gt;. Due to the usage of &lt;code&gt;TTL&lt;/code&gt; its content will be removed after 20 seconds&amp;hellip; hence the column for lock will become &lt;code&gt;null&lt;/code&gt;, #$@&amp;amp;%!!! There is no row level consistency in Cassandra, #$@&amp;amp;%!!!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://datanerds.io/img/wat/wat7.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;workaround&#34;&gt;Workaround&lt;/h3&gt;

&lt;p&gt;The latter release &lt;code&gt;UPDATE&lt;/code&gt; will also be executed using LWT. When a tie happens using LWT it will return with &lt;code&gt;applied = false&lt;/code&gt;. In these cases we just retry the release query&amp;hellip;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://datanerds.io/img/mindblown.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;possible-cassandra-improvements&#34;&gt;Possible Cassandra Improvements&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;The server should log timestamp ties. We were just lucky to find the glitch in the data: &lt;a href=&#34;https://issues.apache.org/jira/browse/CASSANDRA-12587&#34;&gt;https://issues.apache.org/jira/browse/CASSANDRA-12587&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Since the origin of the competing query is the same process, a sequence number should be sufficient to define order: &lt;a href=&#34;https://issues.apache.org/jira/browse/CASSANDRA-6123&#34;&gt;https://issues.apache.org/jira/browse/CASSANDRA-6123&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;[1] - &lt;a href=&#34;http://cassandra.apache.org/doc/latest/faq/index.html#what-happens-if-two-updates-are-made-with-the-same-timestamp&#34;&gt;http://cassandra.apache.org/doc/latest/faq/index.html#what-happens-if-two-updates-are-made-with-the-same-timestamp&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>